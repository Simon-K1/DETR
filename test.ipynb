{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# a=torch.tensor([[1,2,3],[2,3,4]])\n",
    "# print((a.shape))\n",
    "# amax=a.max(-1)\n",
    "# asum=a.sum(-1)\n",
    "# asum=asum.unsqueeze(-1)\n",
    "# a-asum\n",
    "\n",
    "x=torch.rand(16,6,197,768)\n",
    "# testMax=x.max(-1)\n",
    "# print(testMax.values.shape)\n",
    "# Row_Sum=(torch.pow(2,x-x.max(-1).values.unsqueeze(-1))).sum(-1)#先算一下每一行的指数累加和作为分母\n",
    "# print(Row_Sum.unsqueeze(-1).shape)\n",
    "# # print(Row_Sum.unsqueeze(-1).expand(16,6,197,768))\n",
    "# Row_Sum=Row_Sum.unsqueeze(-1).expand(16,6,197,768)\n",
    "# Row_Sum.shape[0:3]\n",
    "\n",
    "Row_Sum=(torch.pow(2,x-x.max(-1).values.unsqueeze(-1))).sum(-1)#先算一下每一行的指数累加和作为分母\n",
    "Row_Sum=Row_Sum.unsqueeze(-1)\n",
    "Row_Sum=Row_Sum.expand(Row_Sum.shape[0],Row_Sum.shape[1],Row_Sum.shape[2],x.shape[-1])\n",
    "x=torch.pow(2,x-x.max(-1).values.unsqueeze(-1))/Row_Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [2., 2., 2., 2., 2.],\n",
      "         [3., 3., 3., 3., 3.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[[1], [2], [3]]])\n",
    "print(x.expand(1,3, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1294, -0.0723, -0.0390,  ...,  0.0440,  0.2447, -0.3020],\n",
       "          [ 0.1303, -0.0731, -0.0390,  ...,  0.0432,  0.2448, -0.3018],\n",
       "          [ 0.1290, -0.0730, -0.0389,  ...,  0.0440,  0.2452, -0.3017],\n",
       "          ...,\n",
       "          [ 0.1293, -0.0728, -0.0390,  ...,  0.0441,  0.2447, -0.3022],\n",
       "          [ 0.1292, -0.0726, -0.0389,  ...,  0.0439,  0.2446, -0.3022],\n",
       "          [ 0.1292, -0.0725, -0.0389,  ...,  0.0445,  0.2451, -0.3019]],\n",
       " \n",
       "         [[ 0.1251, -0.0854, -0.0210,  ...,  0.0629,  0.2257, -0.2848],\n",
       "          [ 0.1245, -0.0854, -0.0215,  ...,  0.0625,  0.2261, -0.2849],\n",
       "          [ 0.1245, -0.0852, -0.0216,  ...,  0.0626,  0.2254, -0.2856],\n",
       "          ...,\n",
       "          [ 0.1251, -0.0857, -0.0222,  ...,  0.0630,  0.2257, -0.2852],\n",
       "          [ 0.1255, -0.0857, -0.0214,  ...,  0.0632,  0.2257, -0.2855],\n",
       "          [ 0.1250, -0.0853, -0.0215,  ...,  0.0625,  0.2255, -0.2853]],\n",
       " \n",
       "         [[ 0.1275, -0.0699, -0.0232,  ...,  0.0476,  0.2615, -0.2791],\n",
       "          [ 0.1276, -0.0695, -0.0234,  ...,  0.0471,  0.2615, -0.2794],\n",
       "          [ 0.1271, -0.0689, -0.0230,  ...,  0.0471,  0.2622, -0.2792],\n",
       "          ...,\n",
       "          [ 0.1271, -0.0694, -0.0237,  ...,  0.0477,  0.2621, -0.2789],\n",
       "          [ 0.1270, -0.0696, -0.0231,  ...,  0.0473,  0.2625, -0.2798],\n",
       "          [ 0.1267, -0.0689, -0.0235,  ...,  0.0476,  0.2625, -0.2794]]],\n",
       "        grad_fn=<TransposeBackward0>),\n",
       " tensor([[[0.0052, 0.0055, 0.0052,  ..., 0.0050, 0.0048, 0.0050],\n",
       "          [0.0051, 0.0052, 0.0052,  ..., 0.0049, 0.0048, 0.0051],\n",
       "          [0.0050, 0.0054, 0.0052,  ..., 0.0050, 0.0049, 0.0052],\n",
       "          ...,\n",
       "          [0.0051, 0.0053, 0.0052,  ..., 0.0050, 0.0048, 0.0052],\n",
       "          [0.0051, 0.0053, 0.0051,  ..., 0.0049, 0.0048, 0.0053],\n",
       "          [0.0050, 0.0054, 0.0051,  ..., 0.0050, 0.0049, 0.0052]],\n",
       " \n",
       "         [[0.0051, 0.0047, 0.0049,  ..., 0.0053, 0.0053, 0.0052],\n",
       "          [0.0050, 0.0048, 0.0052,  ..., 0.0054, 0.0053, 0.0051],\n",
       "          [0.0050, 0.0048, 0.0051,  ..., 0.0052, 0.0052, 0.0052],\n",
       "          ...,\n",
       "          [0.0051, 0.0048, 0.0050,  ..., 0.0053, 0.0052, 0.0051],\n",
       "          [0.0050, 0.0048, 0.0049,  ..., 0.0053, 0.0052, 0.0051],\n",
       "          [0.0052, 0.0048, 0.0050,  ..., 0.0052, 0.0053, 0.0050]],\n",
       " \n",
       "         [[0.0047, 0.0054, 0.0051,  ..., 0.0050, 0.0051, 0.0051],\n",
       "          [0.0047, 0.0052, 0.0050,  ..., 0.0051, 0.0052, 0.0051],\n",
       "          [0.0046, 0.0051, 0.0050,  ..., 0.0048, 0.0052, 0.0050],\n",
       "          ...,\n",
       "          [0.0048, 0.0053, 0.0050,  ..., 0.0050, 0.0051, 0.0050],\n",
       "          [0.0048, 0.0052, 0.0049,  ..., 0.0050, 0.0050, 0.0051],\n",
       "          [0.0048, 0.0053, 0.0051,  ..., 0.0050, 0.0052, 0.0049]]],\n",
       "        grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "Attn=torch.nn.MultiheadAttention(768,6,batch_first=True)\n",
    "Qkv=torch.rand(3,197,768)\n",
    "Attn(Qkv,Qkv,Qkv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "495274a28bdb076e4e5d468612a890f31d5e619c1dd6c8cb530d5f7b822d194c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
