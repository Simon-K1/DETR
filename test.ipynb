{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# a=torch.tensor([[1,2,3],[2,3,4]])\n",
    "# print((a.shape))\n",
    "# amax=a.max(-1)\n",
    "# asum=a.sum(-1)\n",
    "# asum=asum.unsqueeze(-1)\n",
    "# a-asum\n",
    "\n",
    "x=torch.rand(16,6,197,768)\n",
    "# testMax=x.max(-1)\n",
    "# print(testMax.values.shape)\n",
    "# Row_Sum=(torch.pow(2,x-x.max(-1).values.unsqueeze(-1))).sum(-1)#先算一下每一行的指数累加和作为分母\n",
    "# print(Row_Sum.unsqueeze(-1).shape)\n",
    "# # print(Row_Sum.unsqueeze(-1).expand(16,6,197,768))\n",
    "# Row_Sum=Row_Sum.unsqueeze(-1).expand(16,6,197,768)\n",
    "# Row_Sum.shape[0:3]\n",
    "\n",
    "Row_Sum=(torch.pow(2,x-x.max(-1).values.unsqueeze(-1))).sum(-1)#先算一下每一行的指数累加和作为分母\n",
    "Row_Sum=Row_Sum.unsqueeze(-1)\n",
    "Row_Sum=Row_Sum.expand(Row_Sum.shape[0],Row_Sum.shape[1],Row_Sum.shape[2],x.shape[-1])\n",
    "x=torch.pow(2,x-x.max(-1).values.unsqueeze(-1))/Row_Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [2., 2., 2., 2., 2.],\n",
      "         [3., 3., 3., 3., 3.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[[1], [2], [3]]])\n",
    "print(x.expand(1,3, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.arange(12)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3]],\n",
       "\n",
       "        [[ 4,  5],\n",
       "         [ 6,  7]],\n",
       "\n",
       "        [[ 8,  9],\n",
       "         [10, 11]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.arange(12).reshape(3,2,2).flatten(1)\n",
    "print(a)#按第1个维度展开，你应该能理解，就是把这个维度的所有元素都展开\n",
    "a=torch.arange(12).reshape(3,2,2).flatten(2)\n",
    "a#可以认为按最后一个维度展开不会有任何改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torchvision.models import AlexNet\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "\n",
    "blocks=nn.Transformer(d_model=768,nhead=12, num_encoder_layers=1,num_decoder_layers=1)\n",
    "print(blocks)\n",
    "x=torch.rand(1,197,768)\n",
    "out=blocks(x,x)\n",
    "\n",
    "g = make_dot(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import AlexNet\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from itertools import repeat\n",
    "import collections.abc\n",
    "#Trasnforemr相关组件====================================\n",
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, collections.abc.Iterable):\n",
    "            return x\n",
    "        return tuple(repeat(x, n))\n",
    "\n",
    "    return parse\n",
    "to_2tuple = _ntuple(2)\n",
    "\n",
    "class PatchEmbed(nn.Module):#默认为vit—base\n",
    "    # patch_size=16,\n",
    "    # embed_dim=768,\n",
    "    # depth=12,\n",
    "    # num_heads=12,\n",
    "    # mlp_ratio=4,\n",
    "\n",
    "    def __init__(self,In_Channels:int=1,Out_Channels:int=768,img_size:int=224,patch_size:int=16):\n",
    "        super(PatchEmbed,self).__init__()\n",
    "        self.proj=nn.Conv2d(in_channels=In_Channels,out_channels=Out_Channels, kernel_size=patch_size,stride=patch_size,)\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.grid_size = (img_size[0] // patch_size[0],\n",
    "                          img_size[1] // patch_size[1])\n",
    "        self.num_patches = self.grid_size[0] * self.grid_size[1]\n",
    "    def forward(self,x):\n",
    "        print(x.shape)\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "def Test_PatchEmbed():\n",
    "    model=PatchEmbed(In_Channels=1,Out_Channels=384)\n",
    "    model(torch.rand(1,1,224,224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(2,3,224,224)\n",
    "Embedding_Layer=PatchEmbed(3,768,224,224)\n",
    "Single_Encoder = nn.TransformerEncoderLayer(d_model=768, nhead=8,batch_first=True,norm_first=True)#在Vit中的norm需要位于atten和FF之前\n",
    "Encoders= nn.TransformerEncoder(Single_Encoder,num_layers=1,norm=None)#构建多个连在一起的Encoder\n",
    "                                                                      #nomrm 就是在末尾加一个normlization\n",
    "\n",
    "x=Embedding_Layer(x)\n",
    "print(x.shape)\n",
    "x=Encoders(x)                                                 \n",
    "\n",
    "print(x.shape)\n",
    "print(Single_Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i in(1,5):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "495274a28bdb076e4e5d468612a890f31d5e619c1dd6c8cb530d5f7b822d194c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
