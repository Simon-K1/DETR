{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14., 12., 12.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a=[13.5,12.5,11.5]\n",
    "a=torch.tensor(a)\n",
    "a.round()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -2., -0.,  0.,  2.,  2.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([-2.5000 , -1.5000,   -0.5000,    0.5000 ,   1.5000  ,  2.5000]).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3, 4],\n",
       "         [1, 2, 3, 4]],\n",
       "\n",
       "        [[1, 2, 3, 4],\n",
       "         [1, 2, 3, 4]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.tensor([[[1,2,3,4],[1,2,3,4]],[[1,2,3,4],[1,2,3,4]]])\n",
    "Y=torch.tensor([1])\n",
    "X*Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "x =torch.tensor([[[1,2,3,4]]])\n",
    "x.shape\n",
    "x.expand(1,4,4)\n",
    "for i in range(x.shape[2]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 197])\n",
      "torch.Size([1, 197, 384])\n",
      "torch.Size([1, 197, 384]) tensor([[[189.5131, 189.5131, 189.5131,  ..., 189.5131, 189.5131, 189.5131],\n",
      "         [185.2674, 185.2674, 185.2674,  ..., 185.2674, 185.2674, 185.2674],\n",
      "         [202.7715, 202.7715, 202.7715,  ..., 202.7715, 202.7715, 202.7715],\n",
      "         ...,\n",
      "         [187.6707, 187.6707, 187.6707,  ..., 187.6707, 187.6707, 187.6707],\n",
      "         [192.0286, 192.0286, 192.0286,  ..., 192.0286, 192.0286, 192.0286],\n",
      "         [187.3412, 187.3412, 187.3412,  ..., 187.3412, 187.3412, 187.3412]]])\n",
      "torch.Size([1, 384, 1])\n",
      "torch.Size([1, 197, 384]) tensor([[[0.3004, 0.3004, 0.3004,  ..., 0.3004, 0.3004, 0.3004],\n",
      "         [0.9279, 0.9279, 0.9279,  ..., 0.9279, 0.9279, 0.9279],\n",
      "         [0.1231, 0.1231, 0.1231,  ..., 0.1231, 0.1231, 0.1231],\n",
      "         ...,\n",
      "         [0.4158, 0.4158, 0.4158,  ..., 0.4158, 0.4158, 0.4158],\n",
      "         [0.9842, 0.9842, 0.9842,  ..., 0.9842, 0.9842, 0.9842],\n",
      "         [0.4404, 0.4404, 0.4404,  ..., 0.4404, 0.4404, 0.4404]]])\n"
     ]
    }
   ],
   "source": [
    "out_scale=torch.tensor(0.234)\n",
    "in_scale=torch.rand(1,1,384)\n",
    "channel_nums=384\n",
    "SCALE=torch.rand(1,1,384)\n",
    "x_q=torch.rand(16,197,384)\n",
    "x_q_sum=x_q.sum(dim=-1)\n",
    "std_x_q =  torch.sqrt(#std标准差也就是加入alpha后每一行的标准差，\n",
    "                channel_nums * (x_q**2).sum(dim=-1) - x_q.sum(dim=-1)**2)\n",
    "print(x_q_sum.shape)\n",
    "for i in range(x_q.shape[2]):#x_q:[1,197,384]\n",
    "    x_q[:,:,i]=(x_q[:,:,i]*channel_nums-x_q_sum)/std_x_q\n",
    "    \n",
    "for i in range(x_q.shape[1]):\n",
    "    x_q[:,i,:]=x_q[:,i,:]*in_scale\n",
    "\n",
    "beta=torch.rand(384)\n",
    "\n",
    "\n",
    "\n",
    "X_q=torch.rand(1,197,384)\n",
    "print(X_q.shape)\n",
    "X_Mean=X_q.sum(dim=-1).unsqueeze(-1)*torch.ones(384)\n",
    "print(X_Mean.shape,X_Mean)\n",
    "\n",
    "\n",
    "Bias=torch.rand(384)\n",
    "Bias=Bias.reshape(1,-1,1)\n",
    "print(Bias.shape)\n",
    "Bias=Bias*torch.ones(197)\n",
    "print(Bias.transpose(-1,-2).shape,Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4387, 0.7669, 0.2106,  ..., 0.8591, 0.9018, 0.4752],\n",
      "        [0.4014, 0.7293, 0.1607,  ..., 0.2853, 0.2908, 0.7871],\n",
      "        [0.2099, 0.5888, 0.8882,  ..., 0.1855, 0.9568, 0.5268],\n",
      "        ...,\n",
      "        [0.8973, 0.6117, 0.1119,  ..., 0.9328, 0.6377, 0.8109],\n",
      "        [0.0457, 0.5935, 0.6763,  ..., 0.4758, 0.0696, 0.9165],\n",
      "        [0.2328, 0.5865, 0.9871,  ..., 0.3980, 0.9654, 0.4865]])\n",
      "torch.Size([16, 197])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 1, 1])\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "batch=16\n",
    "x_q=torch.rand(batch,197,384)#构造输入\n",
    "in_scale=torch.rand(1,1,384)\n",
    "out_scale=torch.rand(1)\n",
    "channel_nums=x_q.shape[-1]#获取通道数\n",
    "print(x_q[0,:,:])\n",
    "\n",
    "x_q=(x_q/in_scale).round()\n",
    "M1=x_q.sum(dim=-1)\n",
    "print(M1.shape)\n",
    "print(M1[:,1].shape)\n",
    "print(M1[:,1].reshape(16,-1,1).shape)\n",
    "#然后让每一行的点减去对应行的sum\n",
    "std_x_q = torch.sqrt(#std标准差也就是加入alpha后每一行的标准差，\n",
    "                channel_nums * (x_q**2).sum(dim=-1) - x_q.sum(dim=-1)**2)#[1,197]\n",
    "for i in range(M1.shape[-1]):#对于每一行来说，都是[16,384]维，对于M1的每一行来说，都是[16]维\n",
    "    x_q[:,i,:]=(x_q[:,i,:]-M1[:,i].reshape(batch,-1))/std_x_q[:,i].reshape(batch,-1)\n",
    "\n",
    "\n",
    "Gama=torch.rand(1,384)\n",
    "Beta=torch.rand(1,384)\n",
    "for i in range(x_q.shape[1]):#对于每一行来说\n",
    "    x_q[:,i,:]=(x_q[:,i,:]*Gama+Beta).round()\n",
    "# x=torch.tensor([[[1,2,3],[4,5,6]]])\n",
    "# M1=x.sum(dim=-1)\n",
    "# print(x)\n",
    "# print(M1)\n",
    "# print(x[:,1,:]-M1[:,1])\n",
    "a=torch.pow(2,torch.tensor(32))\n",
    "topk=(1,)\n",
    "print(topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#研究acuracy是如何计算的\n",
    "output=torch.rand(16,1000)#16个batch，1000个类的概率\n",
    "topk=(1,5)\n",
    "maxk=max(topk)\n",
    "_, pred = output.topk(maxk, 1, True, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Transformer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "495274a28bdb076e4e5d468612a890f31d5e619c1dd6c8cb530d5f7b822d194c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
