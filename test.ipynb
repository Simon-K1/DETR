{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14., 12., 12.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a=[13.5,12.5,11.5]\n",
    "a=torch.tensor(a)\n",
    "a.round()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -2., -0.,  0.,  2.,  2.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([-2.5000 , -1.5000,   -0.5000,    0.5000 ,   1.5000  ,  2.5000]).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3, 4],\n",
       "         [1, 2, 3, 4]],\n",
       "\n",
       "        [[1, 2, 3, 4],\n",
       "         [1, 2, 3, 4]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.tensor([[[1,2,3,4],[1,2,3,4]],[[1,2,3,4],[1,2,3,4]]])\n",
    "Y=torch.tensor([1])\n",
    "\n",
    "X*Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x =torch.tensor([[[1,2,3,4]]])\n",
    "x.shape\n",
    "x.expand(1,4,4)\n",
    "for i in x[0,0,:]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out_scale\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mtensor(\u001b[39m0.234\u001b[39m)\n\u001b[0;32m      2\u001b[0m in_scale\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m384\u001b[39m)\n\u001b[0;32m      3\u001b[0m channel_nums\u001b[39m=\u001b[39m\u001b[39m384\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "out_scale=torch.tensor(0.234)\n",
    "in_scale=torch.rand(1,1,384)\n",
    "channel_nums=384\n",
    "SCALE=torch.rand(1,1,384)\n",
    "x_q=torch.rand(16,197,384)\n",
    "x_q_sum=x_q.sum(dim=-1)\n",
    "std_x_q =  torch.sqrt(#std标准差也就是加入alpha后每一行的标准差，\n",
    "                channel_nums * (x_q**2).sum(dim=-1) - x_q.sum(dim=-1)**2)\n",
    "print(x_q_sum.shape)\n",
    "for i in range(x_q.shape[2]):#x_q:[1,197,384]\n",
    "    x_q[:,:,i]=(x_q[:,:,i]*channel_nums-x_q_sum)/std_x_q\n",
    "    \n",
    "for i in range(x_q.shape[1]):\n",
    "    x_q[:,i,:]=x_q[:,i,:]*in_scale\n",
    "\n",
    "beta=torch.rand(384)\n",
    "\n",
    "\n",
    "\n",
    "X_q=torch.rand(1,197,384)\n",
    "print(X_q.shape)\n",
    "X_Mean=X_q.sum(dim=-1).unsqueeze(-1)*torch.ones(384)\n",
    "print(X_Mean.shape,X_Mean)\n",
    "\n",
    "\n",
    "Bias=torch.rand(384)\n",
    "Bias=Bias.reshape(1,-1,1)\n",
    "print(Bias.shape)\n",
    "Bias=Bias*torch.ones(197)\n",
    "print(Bias.transpose(-1,-2).shape,Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8284, 0.8615, 0.9001,  ..., 0.4303, 0.8895, 0.7683],\n",
      "        [0.1498, 0.9806, 0.2665,  ..., 0.1643, 0.7077, 0.8185],\n",
      "        [0.8216, 0.4132, 0.8983,  ..., 0.3648, 0.8573, 0.3017],\n",
      "        ...,\n",
      "        [0.5421, 0.3475, 0.2392,  ..., 0.4069, 0.5456, 0.9214],\n",
      "        [0.9650, 0.2893, 0.0048,  ..., 0.8635, 0.5091, 0.3144],\n",
      "        [0.7948, 0.3334, 0.4086,  ..., 0.1863, 0.5976, 0.7749]])\n",
      "torch.Size([16, 197])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 1, 1])\n",
      "(1,)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "batch=16\n",
    "x_q=torch.rand(batch,197,384)#构造输入\n",
    "in_scale=torch.rand(1,1,384)\n",
    "out_scale=torch.rand(1)\n",
    "channel_nums=x_q.shape[-1]#获取通道数\n",
    "print(x_q[0,:,:])\n",
    "\n",
    "x_q=(x_q/in_scale).round()\n",
    "M1=x_q.sum(dim=-1)\n",
    "print(M1.shape)\n",
    "print(M1[:,1].shape)\n",
    "print(M1[:,1].reshape(16,-1,1).shape)\n",
    "#然后让每一行的点减去对应行的sum\n",
    "std_x_q = torch.sqrt(#std标准差也就是加入alpha后每一行的标准差，\n",
    "                channel_nums * (x_q**2).sum(dim=-1) - x_q.sum(dim=-1)**2)#[1,197]\n",
    "for i in range(M1.shape[-1]):#对于每一行来说，都是[16,384]维，对于M1的每一行来说，都是[16]维\n",
    "    x_q[:,i,:]=(x_q[:,i,:]-M1[:,i].reshape(batch,-1))/std_x_q[:,i].reshape(batch,-1)\n",
    "\n",
    "\n",
    "Gama=torch.rand(1,384)\n",
    "Beta=torch.rand(1,384)\n",
    "for i in range(x_q.shape[1]):#对于每一行来说\n",
    "    x_q[:,i,:]=(x_q[:,i,:]*Gama+Beta).round()\n",
    "# x=torch.tensor([[[1,2,3],[4,5,6]]])\n",
    "# M1=x.sum(dim=-1)\n",
    "# print(x)\n",
    "# print(M1)\n",
    "# print(x[:,1,:]-M1[:,1])\n",
    "a=torch.pow(2,torch.tensor(32))\n",
    "topk=(1,)\n",
    "print(topk)\n",
    "\n",
    "\n",
    "print(Gama.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#研究acuracy是如何计算的\n",
    "output=torch.rand(16,1000)#16个batch，1000个类的概率\n",
    "topk=(1,5)\n",
    "maxk=max(topk)\n",
    "_, pred = output.topk(maxk, 1, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "out_scale=torch.tensor(0.0234)\n",
    "Gama=((torch.rand(1,1,384)/out_scale*torch.pow(2, torch.tensor(32))).round()/torch.pow(2, torch.tensor(32))).round()\n",
    "Gama\n",
    "Beta=((torch.rand(1,1,384)/out_scale*torch.pow(2, torch.tensor(32))).round()/torch.pow(2, torch.tensor(32))).round()\n",
    "with open ('Scale_Bias.txt','a') as ff:\n",
    "    for i in range(Gama.shape[-1]):\n",
    "        ff.write('%02x%02x'%(int(Gama[0,0,i].item())&0xff,int(Beta[0,0,i].item())&0xff))\n",
    "        ff.write(\"\\n\")\n",
    "ff.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m a\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mtensor(\u001b[39m100.1\u001b[39m)\u001b[39m.\u001b[39mitem()\n\u001b[0;32m      2\u001b[0m \u001b[39mint\u001b[39m(a)\n\u001b[1;32m----> 3\u001b[0m a\u001b[39m.\u001b[39;49mtype()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "a=torch.tensor(100.1).item()\n",
    "int(a)\n",
    "a.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0a-c\n"
     ]
    }
   ],
   "source": [
    "num=10\n",
    "b=-12\n",
    "print('%02x%02x'%(num,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec:-4 hex:FC\n",
      "dec:-3 hex:FD\n",
      "dec:-2 hex:FE\n",
      "dec:-1 hex:FF\n",
      "dec:0 hex:00\n",
      "dec:1 hex:01\n",
      "dec:2 hex:02\n",
      "dec:3 hex:03\n",
      "dec:4 hex:04\n"
     ]
    }
   ],
   "source": [
    "for x in range(-4,5):\n",
    "    print (\"dec:%d hex:%02X\" % (x, x & 0xff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-7.5648e+04, -7.5647e+04, -7.5646e+04,  ..., -7.5267e+04,\n",
      "          -7.5266e+04, -7.5265e+04],\n",
      "         [-7.5264e+04, -7.5263e+04, -7.5262e+04,  ..., -7.4883e+04,\n",
      "          -7.4882e+04, -7.4881e+04],\n",
      "         [-7.4880e+04, -7.4879e+04, -7.4878e+04,  ..., -7.4499e+04,\n",
      "          -7.4498e+04, -7.4497e+04],\n",
      "         ...,\n",
      "         [-1.1510e+03, -1.1500e+03, -1.1490e+03,  ..., -7.7001e+02,\n",
      "          -7.6901e+02, -7.6801e+02],\n",
      "         [-7.6701e+02, -7.6601e+02, -7.6501e+02,  ..., -3.8601e+02,\n",
      "          -3.8501e+02, -3.8401e+02],\n",
      "         [-3.8301e+02, -3.8201e+02, -3.8101e+02,  ..., -2.0000e+00,\n",
      "          -1.0000e+00,  0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x_q=(torch.linspace(-197*384,0,197*384)).reshape(1,197,384)\n",
    "print(x_q)\n",
    "with open ('Xq_LayerNorm.txt','a') as ff:\n",
    "    for i in range(x_q.shape[-2]):\n",
    "        for j in range(x_q.shape[-1]):\n",
    "            ff.write('%02x'%(int(x_q[0,i,j].item())&0xff))\n",
    "            ff.write(\"\\n\")\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6, 15]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(30., device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "fuck=torch.tensor([[[1,2,3],[4,5,6]]])\n",
    "fuck_sum=fuck.sum(dim=-1)\n",
    "print(fuck_sum)\n",
    "\n",
    "fuck=torch.tensor([  -2.,    0.,    2.,  -76.,  -46.,  -62.,   20.,  -64.,    2.,  -96.,\n",
    "           0.,    2.,    0.,  -62., -108.,   46.,  -32.,   12.,   48.,    2.,\n",
    "         -14.,   14.,    0.,   -2.,  -20.,  -20.,  -12.,  146.,   34.,   -2.,\n",
    "           0.,    0.,    4.,   46.,    0.,  -92.,    0.,   -2.,   12.,   28.,\n",
    "          -2.,   14.,    0.,  124.,   16.,   16.,  -30.,   30.,   12.,   50.,\n",
    "          12.,   -4.,   80.,   48.,    4.,    4.,    2.,   32.,   32.,   30.,\n",
    "         -20.,    0.,  -12.,   32.,    4.,  -50.,    4.,  -14.,  -12.,    2.,\n",
    "          52.,  -16.,  -76.,  -80.,  -36.,   76.,   96.,    0.,  -12.,    0.,\n",
    "          66.,    2.,   16.,    0.,  -66.,   14.,    0.,   32.,   14.,    2.,\n",
    "           4.,   12.,    0.,   16.,    0.,   -4.,   22.,   12.,   16.,   20.,\n",
    "           4.,    0.,   64.,  -48.,  -64.,   12.,   -2.,   14.,  -14.,    0.,\n",
    "          36.,  -48.,  -14.,   14.,  -12.,    0.,   12.,    0.,   92.,   20.,\n",
    "         -50., -126.,    2.,   48.,  -12.,  -24.,  -32.,   22.,  -12.,   34.,\n",
    "        -126.,   14.,  -12.,    0.,  -76.,    0.,   66.,    2.,  -20.,    2.,\n",
    "          -2.,   12.,   82.,  -16.,   -2.,   12.,    4.,    4.,   32.,  -30.,\n",
    "          32.,   16.,    0.,    2.,   -2.,  -14.,  -12.,   16.,  -20.,  124.,\n",
    "          -2.,    2.,   66.,   20.,  -12.,    0.,   62.,   80.,   44.,  -46.,\n",
    "          44.,   -4.,  -14.,  -30.,    2.,   32.,   20.,  -16.,   -2.,    0.,\n",
    "         -66.,   -4.,  -64.,  -12.,   20.,    0.,    4.,  -12.,  -82.,  -48.,\n",
    "         -14.,  -14.,   -4., -156.,  -48.,  -10.,   66.,  -76.,    4.,  -14.,\n",
    "          62.,   12.,    0.,  -64.,   -2.,  -12.,   -2.,    4.,  -34.,   -2.,\n",
    "          16.,   -2.,   14.,    2.,    0.,  -16.,   12.,   14.,    0.,   50.,\n",
    "          -4.,   16.,   32.,   -2.,  -14.,  -12.,  -92.,  -48.,    2.,  -52.,\n",
    "          -2.,   -4.,   80.,   16.,  -28.,  -30.,   -4.,   32.,   -2.,   -4.,\n",
    "          16.,  -16.,   -4.,  -32.,   46.,  -16.,    2.,    4.,  -50.,  100.,\n",
    "          20.,    2.,  -50.,  -98.,   -2.,  -12.,  238.,   12.,   -4.,    2.,\n",
    "          -2.,   44.,   46.,   30.,   20.,   14.,  -20.,   12.,   -2.,  -62.,\n",
    "          -4.,    0.,    0.,  -32.,  -30.,   12.,    2.,    0.,   78.,    4.,\n",
    "           2.,   20.,    0.,    4.,    0.,   -4.,  -30.,    0.,   -2.,  -64.,\n",
    "          30.,    0.,   14.,   -4.,    4.,  -12.,  -16.,   34.,  -12.,   -2.,\n",
    "          58.,   46.,    4.,    0.,  -14.,    0.,   12.,   78.,   80.,  -20.,\n",
    "          34.,  -12.,    0.,   30.,    2.,   -2.,    0.,    0.,   28.,    4.,\n",
    "          32.,    0.,   -2.,   78.,    6.,   48.,   -4.,  -14.,    0.,   34.,\n",
    "         -34., -784.,  -12.,   -2.,   16.,   68.,    2.,   66.,    4.,  -30.,\n",
    "          12.,    2.,   62.,   12.,   30.,   28.,  -14.,    4.,   -4.,  -14.,\n",
    "          96.,    4.,   32.,  -62.,   32.,  -80.,  -14.,  -64.,    2.,    2.,\n",
    "           0.,   16.,    4.,  -12.,    0.,  -66.,   24.,  -20.,  -14.,  -24.,\n",
    "           2.,    0.,   20.,    0.,   36.,   12.,    4.,   -4.,    2.,   -4.,\n",
    "           0.,    2.,   -4.,   16.], device='cuda:0')\n",
    "fuck.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Transformer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "495274a28bdb076e4e5d468612a890f31d5e619c1dd6c8cb530d5f7b822d194c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
