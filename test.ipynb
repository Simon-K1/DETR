{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14., 12., 12.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a=[13.5,12.5,11.5]\n",
    "a=torch.tensor(a)\n",
    "a.round()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -2., -0.,  0.,  2.,  2.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([-2.5000 , -1.5000,   -0.5000,    0.5000 ,   1.5000  ,  2.5000]).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3, 4],\n",
       "         [1, 2, 3, 4]],\n",
       "\n",
       "        [[1, 2, 3, 4],\n",
       "         [1, 2, 3, 4]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.tensor([[[1,2,3,4],[1,2,3,4]],[[1,2,3,4],[1,2,3,4]]])\n",
    "Y=torch.tensor([1])\n",
    "\n",
    "X*Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x =torch.tensor([[[1,2,3,4]]])\n",
    "x.shape\n",
    "x.expand(1,4,4)\n",
    "for i in x[0,0,:]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out_scale\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mtensor(\u001b[39m0.234\u001b[39m)\n\u001b[0;32m      2\u001b[0m in_scale\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m384\u001b[39m)\n\u001b[0;32m      3\u001b[0m channel_nums\u001b[39m=\u001b[39m\u001b[39m384\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "out_scale=torch.tensor(0.234)\n",
    "in_scale=torch.rand(1,1,384)\n",
    "channel_nums=384\n",
    "SCALE=torch.rand(1,1,384)\n",
    "x_q=torch.rand(16,197,384)\n",
    "x_q_sum=x_q.sum(dim=-1)\n",
    "std_x_q =  torch.sqrt(#std标准差也就是加入alpha后每一行的标准差，\n",
    "                channel_nums * (x_q**2).sum(dim=-1) - x_q.sum(dim=-1)**2)\n",
    "print(x_q_sum.shape)\n",
    "for i in range(x_q.shape[2]):#x_q:[1,197,384]\n",
    "    x_q[:,:,i]=(x_q[:,:,i]*channel_nums-x_q_sum)/std_x_q\n",
    "    \n",
    "for i in range(x_q.shape[1]):\n",
    "    x_q[:,i,:]=x_q[:,i,:]*in_scale\n",
    "\n",
    "beta=torch.rand(384)\n",
    "\n",
    "\n",
    "\n",
    "X_q=torch.rand(1,197,384)\n",
    "print(X_q.shape)\n",
    "X_Mean=X_q.sum(dim=-1).unsqueeze(-1)*torch.ones(384)\n",
    "print(X_Mean.shape,X_Mean)\n",
    "\n",
    "\n",
    "Bias=torch.rand(384)\n",
    "Bias=Bias.reshape(1,-1,1)\n",
    "print(Bias.shape)\n",
    "Bias=Bias*torch.ones(197)\n",
    "print(Bias.transpose(-1,-2).shape,Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8284, 0.8615, 0.9001,  ..., 0.4303, 0.8895, 0.7683],\n",
      "        [0.1498, 0.9806, 0.2665,  ..., 0.1643, 0.7077, 0.8185],\n",
      "        [0.8216, 0.4132, 0.8983,  ..., 0.3648, 0.8573, 0.3017],\n",
      "        ...,\n",
      "        [0.5421, 0.3475, 0.2392,  ..., 0.4069, 0.5456, 0.9214],\n",
      "        [0.9650, 0.2893, 0.0048,  ..., 0.8635, 0.5091, 0.3144],\n",
      "        [0.7948, 0.3334, 0.4086,  ..., 0.1863, 0.5976, 0.7749]])\n",
      "torch.Size([16, 197])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 1, 1])\n",
      "(1,)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "batch=16\n",
    "x_q=torch.rand(batch,197,384)#构造输入\n",
    "in_scale=torch.rand(1,1,384)\n",
    "out_scale=torch.rand(1)\n",
    "channel_nums=x_q.shape[-1]#获取通道数\n",
    "print(x_q[0,:,:])\n",
    "\n",
    "x_q=(x_q/in_scale).round()\n",
    "M1=x_q.sum(dim=-1)\n",
    "print(M1.shape)\n",
    "print(M1[:,1].shape)\n",
    "print(M1[:,1].reshape(16,-1,1).shape)\n",
    "#然后让每一行的点减去对应行的sum\n",
    "std_x_q = torch.sqrt(#std标准差也就是加入alpha后每一行的标准差，\n",
    "                channel_nums * (x_q**2).sum(dim=-1) - x_q.sum(dim=-1)**2)#[1,197]\n",
    "for i in range(M1.shape[-1]):#对于每一行来说，都是[16,384]维，对于M1的每一行来说，都是[16]维\n",
    "    x_q[:,i,:]=(x_q[:,i,:]-M1[:,i].reshape(batch,-1))/std_x_q[:,i].reshape(batch,-1)\n",
    "\n",
    "\n",
    "Gama=torch.rand(1,384)\n",
    "Beta=torch.rand(1,384)\n",
    "for i in range(x_q.shape[1]):#对于每一行来说\n",
    "    x_q[:,i,:]=(x_q[:,i,:]*Gama+Beta).round()\n",
    "# x=torch.tensor([[[1,2,3],[4,5,6]]])\n",
    "# M1=x.sum(dim=-1)\n",
    "# print(x)\n",
    "# print(M1)\n",
    "# print(x[:,1,:]-M1[:,1])\n",
    "a=torch.pow(2,torch.tensor(32))\n",
    "topk=(1,)\n",
    "print(topk)\n",
    "\n",
    "\n",
    "print(Gama.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#研究acuracy是如何计算的\n",
    "output=torch.rand(16,1000)#16个batch，1000个类的概率\n",
    "topk=(1,5)\n",
    "maxk=max(topk)\n",
    "_, pred = output.topk(maxk, 1, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "out_scale=torch.tensor(0.0234)\n",
    "Gama=((torch.rand(1,1,384)/out_scale*torch.pow(2, torch.tensor(32))).round()/torch.pow(2, torch.tensor(32))).round()\n",
    "Gama\n",
    "Beta=((torch.rand(1,1,384)/out_scale*torch.pow(2, torch.tensor(32))).round()/torch.pow(2, torch.tensor(32))).round()\n",
    "with open ('Scale_Bias.txt','a') as ff:\n",
    "    for i in range(Gama.shape[-1]):\n",
    "        ff.write('%02x%02x'%(int(Gama[0,0,i].item())&0xff,int(Beta[0,0,i].item())&0xff))\n",
    "        ff.write(\"\\n\")\n",
    "ff.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m a\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mtensor(\u001b[39m100.1\u001b[39m)\u001b[39m.\u001b[39mitem()\n\u001b[0;32m      2\u001b[0m \u001b[39mint\u001b[39m(a)\n\u001b[1;32m----> 3\u001b[0m a\u001b[39m.\u001b[39;49mtype()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "a=torch.tensor(100.1).item()\n",
    "int(a)\n",
    "a.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0a-c\n"
     ]
    }
   ],
   "source": [
    "num=10\n",
    "b=-12\n",
    "print('%02x%02x'%(num,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec:-4 hex:FC\n",
      "dec:-3 hex:FD\n",
      "dec:-2 hex:FE\n",
      "dec:-1 hex:FF\n",
      "dec:0 hex:00\n",
      "dec:1 hex:01\n",
      "dec:2 hex:02\n",
      "dec:3 hex:03\n",
      "dec:4 hex:04\n"
     ]
    }
   ],
   "source": [
    "for x in range(-4,5):\n",
    "    print (\"dec:%d hex:%02X\" % (x, x & 0xff))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Transformer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "495274a28bdb076e4e5d468612a890f31d5e619c1dd6c8cb530d5f7b822d194c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
