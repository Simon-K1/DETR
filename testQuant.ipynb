{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_B(S1, S2, S3):  # 第一组  β即N_REAL  +++++求shitf++++\n",
    "    M = (S1 * S2) / S3\n",
    "    M.squeeze()\n",
    "    M=M.cpu()#先将tensor放到cpu上\n",
    "    M = M.numpy()\n",
    "    \n",
    "    daxiao = S2.shape[0]  # 第一层权重的shape[0]是32 shape[0]表示行数 是一维大小位32的列向量\n",
    "    SCALE = np.zeros(daxiao, dtype=np.uint32, order='C')  # 相当于32个输出通道 每个对应一组shift\n",
    "    N_REAL = np.zeros(daxiao, dtype=np.uint32, order='C')\n",
    "    for i, ii in enumerate(M):  # enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标\n",
    "\n",
    "        while not (ii >= 0.5 and ii <= 1.0):  # 左移到（0.5，1） 左移一次相当于*2\n",
    "            ii *= 2\n",
    "        pass\n",
    "        mmmm = ii * (2 ** 32)  # 乘2^32\n",
    "\n",
    "        SCALE[i] = mmmm.astype(np.int32)\n",
    "\n",
    "    for i, ii in enumerate(M):\n",
    "        N_REAL[i] = round(math.log(SCALE[i] / ii, 2)) - 32   # fpga加了1这里要减1,  β值也是m维 相当于存的mmmm\n",
    "        if int(N_REAL[i])<0:\n",
    "            print(\"error\\n\")\n",
    "        if N_REAL[i] !=0:\n",
    "            N_REAL[i]=N_REAL[i]-1\n",
    "\n",
    "    return N_REAL\n",
    "\n",
    "\n",
    "def gen_M_N(S1, S2, S3):  # 第二组求M'即M  ++++++返回scale和shift+++++\n",
    "    daxiao = S2.shape[0]\n",
    "    M = np.zeros(daxiao, dtype=np.uint32, order='C')\n",
    "    N_REAL = gen_B(S1, S2, S3)\n",
    "    M = np.zeros(S2.shape[0])\n",
    "    \n",
    "    for i, ii in enumerate(M):\n",
    "        Scale=(S1*S2[i]/S3).cpu()\n",
    "        # Scale=Scale.numpy\n",
    "        M[i] = (torch.round(Scale * (2 ** (32 + N_REAL[i] + 1)))).numpy()  # s1s2/s3 *2^(32+β+1)\n",
    "    M = M.astype(np.uint32)\n",
    "    # exit()\n",
    "    return M, N_REAL\n",
    "\n",
    "\n",
    "# r_b=s1*s2*q_b\n",
    "# r_b是量化前的bias,q_b是量化后的bias\n",
    "def gen_int_bias(s1, s2, bias_float):  # 求bias/s1s2即bb\n",
    "    aa = bias_float / s1\n",
    "    # print(bias_float)\n",
    "    # exit()\n",
    "    bb = torch.div(aa, s2)  # 对应元素做除法\n",
    "\n",
    "    # for i, m in enumerate(bb):\n",
    "    #     bb[i] = round(m.item())\n",
    "    # bias = bb.int()\n",
    "    return bb\n",
    "\n",
    "\n",
    "def gen_M(s1, s2, s3):\n",
    "    aa = s1 * s2\n",
    "    M = aa / s3\n",
    "    return M\n",
    "\n",
    "\n",
    "def new_bias(z1, q2, bias):  # 求最终的bias=bias/s1s2-q2z1\n",
    "    q2 = q2.type(torch.float64)\n",
    "    bias1 = z1 * q2\n",
    "    shape = bias1.shape\n",
    "    n_bias = np.zeros(shape[0], dtype=np.float64, order='C')\n",
    "    for m in range(shape[0]):  # bias1的维度是M C K K 将C K K 做累加 变成M维\n",
    "        n_bias[m] = bias1[m, :, :, :].sum()  # 从第一组开始一直有m组，m是输出通道数\n",
    "        # print()\n",
    "        n_bias[m] = (bias[m] - n_bias[m])  # 做减法\n",
    "    # print(n_bias) 第一层n_bias是一维32个\n",
    "    # exit()\n",
    "    daxiao = shape[0]  # 第一层是32\n",
    "    SCALE = np.zeros(daxiao, dtype=np.float64, order='C')\n",
    "    # N_REAL = np.zeros(daxiao, dtype=np.float32, order='C')\n",
    "    N_REAL = []\n",
    "    for i, ii in enumerate(n_bias):  # i和ii就是从n_bias中取值\n",
    "        index = 0\n",
    "\n",
    "        while not (abs(ii) >= (2 ** 23) and abs(ii) <= (2 ** 24)):\n",
    "            if index >= 16:  # fpga里面最多移动16位,所有成到16就停止了,这样精度也够了\n",
    "                break\n",
    "            else:\n",
    "                ii *= 2\n",
    "                index = index + 1\n",
    "\n",
    "        N_REAL.append(index)\n",
    "        SCALE[i] = round(ii)\n",
    "    out_bias = []\n",
    "    for index in range(shape[0]):\n",
    "        data_integer_old = ('{:024b}'.format(int(SCALE[index]) & 0xffffff))  # {:024b} 24位2二进制不足补0；& 0xffffff按位与\n",
    "        n = N_REAL[index]\n",
    "        symbol = '0'\n",
    "        if n_bias[index] < 0:  # 符号位\n",
    "            symbol = '1'#这里也不是多此一举，因为如果你给一个uint24，MSB=1，那么你在FPGA那边如何分辨这是正数还是负数，所以还是需要1bit的符号位来帮助fpga做判断的\n",
    "        elif n_bias[index] > 0:\n",
    "            symbol = '0'\n",
    "        data_integer = data_integer_old[8:]\n",
    "        data_decimal = '{:07b}'.format(int(n))\n",
    "        out_bias1 = symbol + str(data_decimal) + str(data_integer_old)  # 1bit+7bit+24bit\n",
    "        a = int(out_bias1, 2)  # 转成int型 out_bias1为二进制 ；a是十进制\n",
    "        out_bias.append(a)  # 一个一个写入out_bias\n",
    "    # print(out_bias)\n",
    "    # exit()\n",
    "    return out_bias\n",
    "\n",
    "\n",
    "def get_add_bias(new, shape, old):  # 补0\n",
    "    for kernel_num in range(shape):\n",
    "        new[kernel_num] = old[kernel_num]\n",
    "    return new\n",
    "\n",
    "\n",
    "def get_add_SCALE(new, shape, old):  # 补0\n",
    "    for kernel_num in range(shape):\n",
    "        new[kernel_num] = old[kernel_num]\n",
    "    return new\n",
    "\n",
    "\n",
    "def get_add_NREAL(new, shape, old):  # 补0\n",
    "    for kernel_num in range(shape):\n",
    "        new[kernel_num] = old[kernel_num]\n",
    "    return new\n",
    "\n",
    "\n",
    "def get_weight(new_weight, shape, weight, inchannel):  # 八入八出操作 输入通道inchannel不固定 输出通道outchannel为8\n",
    "    j = 0\n",
    "\n",
    "    shift_num = 0\n",
    "    for index in range(inchannel):\n",
    "        if (inchannel == (1 << index)):  # index不停左移一位直到与inchannel相等 来判断移了几位   2的shift_num次方=inchannel\n",
    "            shift_num = index\n",
    "            break\n",
    "    # if shape[0] == 32 and shape[1] == 64 and shape[2] == 1:\n",
    "    #     # print(\"shape:\",new_weight.shape)\n",
    "    #     with open('weight_1x1_8i8o(2).txt', 'a')as f:\n",
    "    #         f.write('-' * 40 + '\\n')\n",
    "    #         f.write(str(shape) + '\\n')\n",
    "    for i in range(shape[2]):  # mckk  K\n",
    "        for ii in range(shape[3]):  # K\n",
    "            for kernel_times in range(shape[0] >> 3):  # >>右移三位 因为输出通道outchannel默认为8 卷积核个数\n",
    "                for channel_in_times in range(shape[1] >> shift_num):  # 右移shift_num 输入通道数\n",
    "                    for iii in range(8):  # shape[0] >> 3 右移了3次即2^3 要补8次\n",
    "                        for iiii in range(\n",
    "                                inchannel):  # shape[1] >> shift_num 右移了shift_num即2^shift_num 要补inchannel次(2^shift_num =inchannel)\n",
    "                            # print('++++++++++++++++++')\n",
    "                            weight[j] = new_weight[kernel_times * 8 + iii][channel_in_times * inchannel + iiii][i][ii]\n",
    "                            # if shape[0] == 32 and shape[1] == 64 and shape[2] == 1:\n",
    "                            # with open('weight_1x1_8i8o(2).txt', 'a')as f:\n",
    "                            #     f.write(str(kernel_times * 8 + iii) + ',')\n",
    "                            #     f.write(str(channel_in_times * inchannel + iiii) + ',')\n",
    "                            #     f.write(str(i) + ',')\n",
    "                            #     f.write(str(ii) + '\\n')\n",
    "                            #\n",
    "                            j += 1\n",
    "    # exit()\n",
    "    return weight\n",
    "\n",
    "\n",
    "def add_weight_channel(new_weig, weig, shape):  # 补0 把weig存入new_weig；new_weig是全0，\n",
    "    for kernel_num in range(shape[0]):\n",
    "        for channel_in_num in range(shape[1]):\n",
    "            for row in range(shape[2]):\n",
    "                for col in range(shape[3]):\n",
    "                    new_weig[kernel_num][channel_in_num][row][col] = weig[kernel_num][channel_in_num][row][col]\n",
    "    return new_weig\n",
    "\n",
    "\n",
    "def tensorr(x):\n",
    "    tensor_py = torch.from_numpy(np.load(x))  # 创建tensor\n",
    "    return tensor_py\n",
    "\n",
    "\n",
    "def get_weight2(new_weight, shape, weight):  # 四维权重写成一维\n",
    "    j = 0\n",
    "    for kernel_times in range(shape[0]):\n",
    "        for channel_in_times in range(shape[1]):\n",
    "            for i in range(shape[2]):\n",
    "                for ii in range(shape[3]):\n",
    "                    # print('++++++++++++++++++')\n",
    "                    weight[j] = new_weight[kernel_times][channel_in_times][i][ii]\n",
    "                    j += 1\n",
    "    return weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25073\\AppData\\Local\\Temp\\ipykernel_12988\\3006563256.py:13: RuntimeWarning: overflow encountered in double_scalars\n",
      "  ii *= 2\n"
     ]
    }
   ],
   "source": [
    "S1=torch.rand(1)*0.499+0.001\n",
    "S2=torch.rand(768)*0.499+0.001\n",
    "S3=torch.rand(1)*0.499+0.001\n",
    "bias=torch.rand(1)*0.499+0.001\n",
    "SCALE, N_REAL = gen_M_N(S1, S2, S3)\n",
    "SCALE\n",
    "N_REAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('1010010',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bias_Tmp='1111'\n",
    "BiasAdd=int(Bias_Tmp, 2) - (1 << len(Bias_Tmp))\n",
    "BiasAdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ord() expected a character, but string of length 3 found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mord\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m111\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: ord() expected a character, but string of length 3 found"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
