{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.ao.quantization import get_default_qat_qconfig_mapping\n",
    "from torch.ao.quantization import prepare_fx\n",
    "\n",
    "class Submodule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(5, 5)\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "class M(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(5, 5)\n",
    "        self.sub = Submodule()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sub(x) + x\n",
    "        return x\n",
    "\n",
    "# initialize a floating point model\n",
    "float_model = M().train()\n",
    "# (optional, but preferred) load the weights from pretrained model\n",
    "# float_model.load_weights(...)\n",
    "\n",
    "# define the training loop for quantization aware training\n",
    "def train_loop(model, train_data):\n",
    "    model.train()\n",
    "    for image, target in data_loader:\n",
    "        ...\n",
    "\n",
    "# qconfig is the configuration for how we insert observers for a particular\n",
    "# operator\n",
    "# qconfig = get_default_qconfig(\"fbgemm\")\n",
    "# Example of customizing qconfig:\n",
    "# qconfig = torch.ao.quantization.QConfig(\n",
    "#    activation=FakeQuantize.with_args(observer=MinMaxObserver.with_args(dtype=torch.qint8)),\n",
    "#    weight=FakeQuantize.with_args(observer=MinMaxObserver.with_args(dtype=torch.qint8)))\n",
    "# `activation` and `weight` are constructors of observer module\n",
    "\n",
    "# qconfig_mapping is a collection of quantization configurations, user can\n",
    "# set the qconfig for each operator (torch op calls, functional calls, module calls)\n",
    "# in the model through qconfig_mapping\n",
    "# the following call will get the qconfig_mapping that works best for models\n",
    "# that target \"fbgemm\" backend\n",
    "qconfig_mapping = get_default_qat_qconfig(\"fbgemm\")\n",
    "\n",
    "# We can customize qconfig_mapping in different ways, please take a look at\n",
    "# the doctring for :func:`~torch.ao.quantization.prepare_fx` for different ways\n",
    "# to configure this\n",
    "\n",
    "# example_inputs is a tuple of inputs, that is used to infer the type of the\n",
    "# outputs in the model\n",
    "# currently it's not used, but please make sure model(*example_inputs) runs\n",
    "example_inputs = (torch.randn(1, 3, 224, 224),)\n",
    "\n",
    "# TODO: add backend_config after we split the backend_config for fbgemm and qnnpack\n",
    "# e.g. backend_config = get_default_backend_config(\"fbgemm\")\n",
    "# `prepare_qat_fx` inserts observers in the model based on qconfig_mapping and\n",
    "# backend_config, if the configuration for an operator in qconfig_mapping\n",
    "# is supported in the backend_config (meaning it's supported by the target\n",
    "# hardware), we'll insert fake_quantize modules according to the qconfig_mapping\n",
    "# otherwise the configuration in qconfig_mapping will be ignored\n",
    "# see :func:`~torch.ao.quantization.prepare_fx` for a detailed explanation of\n",
    "# how qconfig_mapping interacts with backend_config\n",
    "prepared_model = prepare_qat_fx(float_model, qconfig_mapping, example_inputs)\n",
    "# Run training\n",
    "train_loop(prepared_model, train_loop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YoloV5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "278897701cc6d4f1b9746803770f5e818cccf5e556f859a8255d5456d962739d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
